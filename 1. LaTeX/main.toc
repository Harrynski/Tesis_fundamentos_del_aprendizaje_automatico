\babel@toc {spanish}{}\relax 
\contentsline {chapter}{\numberline {1}Un acercamiento amistoso a la Teoría del Aprendizaje Estadístico}{3}{chapter.1}%
\contentsline {section}{\numberline {1.1}Introducción}{3}{section.1.1}%
\contentsline {section}{\numberline {1.2}La historia del aprendizaje automático}{4}{section.1.2}%
\contentsline {section}{\numberline {1.3}Conceptos básicos del aprendizaje}{6}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Pérdida y Riesgo}{7}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}Generalización}{9}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}Consistencia}{9}{subsection.1.3.3}%
\contentsline {subsection}{\numberline {1.3.4}Sobreajuste y subajuste}{11}{subsection.1.3.4}%
\contentsline {subsection}{\numberline {1.3.5}Los dilemas sesgo-varianza y estimación-aproximación}{13}{subsection.1.3.5}%
\contentsline {section}{\numberline {1.4}El clasificador de los $k$ vecinos más cercanos}{15}{section.1.4}%
\contentsline {section}{\numberline {1.5}Minimización del riesgo empírico}{19}{section.1.5}%
\contentsline {subsection}{\numberline {1.5.1}La ley de los grandes números}{20}{subsection.1.5.1}%
\contentsline {subsection}{\numberline {1.5.2}Inconsistencia en la minimización del riesgo empírico}{22}{subsection.1.5.2}%
\contentsline {subsection}{\numberline {1.5.3}Convergencia uniforme}{23}{subsection.1.5.3}%
\contentsline {section}{\numberline {1.6}Cotas de generalización y medidas de capacidad}{26}{section.1.6}%
\contentsline {subsection}{\numberline {1.6.1}Simetrización}{27}{subsection.1.6.1}%
\contentsline {subsection}{\numberline {1.6.2}El coeficiente de fragmentación}{29}{subsection.1.6.2}%
\contentsline {subsection}{\numberline {1.6.3}Cotas de convergencia uniforme}{30}{subsection.1.6.3}%
\contentsline {subsection}{\numberline {1.6.4}Cotas de generalización}{32}{subsection.1.6.4}%
\contentsline {subsection}{\numberline {1.6.5}La dimensión VC}{33}{subsection.1.6.5}%
\contentsline {subsection}{\numberline {1.6.6}Complejidad de Rademacher}{35}{subsection.1.6.6}%
\contentsline {subsection}{\numberline {1.6.7}Cotas con grandes márgenes de separación}{36}{subsection.1.6.7}%
\contentsline {subsection}{\numberline {1.6.8}Conclusiones acerca de las cotas de generalización}{38}{subsection.1.6.8}%
\contentsline {chapter}{\numberline {2}La Teoría VC}{39}{chapter.2}%
\contentsline {subsection}{\numberline {2.0.1}Definiciones preliminares}{39}{subsection.2.0.1}%
\contentsline {subsection}{\numberline {2.0.2}La función de crecimiento}{43}{subsection.2.0.2}%
\contentsline {subsection}{\numberline {2.0.3}El Lema de simetrización}{44}{subsection.2.0.3}%
\contentsline {subsection}{\numberline {2.0.4}Condiciones de convergencia uniforme casi segura}{52}{subsection.2.0.4}%
\contentsline {chapter}{\numberline {3}Otros conceptos del Aprendizaje}{64}{chapter.3}%
\contentsline {section}{\numberline {3.1}Consistencia de Bayes y error de aproximación}{64}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Espacios funcionales anidados}{65}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Regularización}{66}{subsection.3.1.2}%
\contentsline {section}{\numberline {3.2}Los teoremas de la chancha y los veinte}{68}{section.3.2}%
