\babel@toc {spanish}{}\relax 
\contentsline {chapter}{\numberline {1}Un acercamiento amistoso a la Teoría del Aprendizaje Estadístico}{3}{chapter.1}%
\contentsline {section}{\numberline {1.1}Introducción}{3}{section.1.1}%
\contentsline {section}{\numberline {1.2}El aprendizaje}{3}{section.1.2}%
\contentsline {section}{\numberline {1.3}La historia del aprendizaje automático}{4}{section.1.3}%
\contentsline {section}{\numberline {1.4}Conceptos básicos del aprendizaje}{6}{section.1.4}%
\contentsline {subsection}{\numberline {1.4.1}Pérdida y Riesgo}{7}{subsection.1.4.1}%
\contentsline {subsection}{\numberline {1.4.2}Generalización}{9}{subsection.1.4.2}%
\contentsline {subsection}{\numberline {1.4.3}Consistencia}{9}{subsection.1.4.3}%
\contentsline {subsection}{\numberline {1.4.4}Sobreajuste y subajuste}{12}{subsection.1.4.4}%
\contentsline {subsection}{\numberline {1.4.5}Los dilemas sesgo-varianza y estimación-aproximación}{13}{subsection.1.4.5}%
\contentsline {section}{\numberline {1.5}El clasificador de los $k$ vecinos más cercanos}{15}{section.1.5}%
\contentsline {section}{\numberline {1.6}Minimización del riesgo empírico}{19}{section.1.6}%
\contentsline {subsection}{\numberline {1.6.1}La ley de los grandes números}{20}{subsection.1.6.1}%
\contentsline {subsection}{\numberline {1.6.2}Inconsistencia en la minimización del riesgo empírico}{22}{subsection.1.6.2}%
\contentsline {subsection}{\numberline {1.6.3}Convergencia uniforme}{23}{subsection.1.6.3}%
\contentsline {section}{\numberline {1.7}Cotas de generalización y medidas de capacidad}{26}{section.1.7}%
\contentsline {subsection}{\numberline {1.7.1}Simetrización}{27}{subsection.1.7.1}%
\contentsline {subsection}{\numberline {1.7.2}El coeficiente de fragmentación}{29}{subsection.1.7.2}%
\contentsline {subsection}{\numberline {1.7.3}Cotas de convergencia uniforme}{30}{subsection.1.7.3}%
\contentsline {subsection}{\numberline {1.7.4}Cotas de generalización}{32}{subsection.1.7.4}%
\contentsline {subsection}{\numberline {1.7.5}La dimensión VC}{33}{subsection.1.7.5}%
\contentsline {subsection}{\numberline {1.7.6}Complejidad de Rademacher}{35}{subsection.1.7.6}%
\contentsline {subsection}{\numberline {1.7.7}Cotas con grandes márgenes de separación}{36}{subsection.1.7.7}%
\contentsline {subsection}{\numberline {1.7.8}Conclusiones acerca de las cotas de generalización}{38}{subsection.1.7.8}%
\contentsline {chapter}{\numberline {2}La Teoría VC}{39}{chapter.2}%
\contentsline {subsection}{\numberline {2.0.1}Definiciones preliminares}{39}{subsection.2.0.1}%
\contentsline {subsection}{\numberline {2.0.2}La función de crecimiento}{43}{subsection.2.0.2}%
\contentsline {subsection}{\numberline {2.0.3}El Lema de simetrización}{44}{subsection.2.0.3}%
\contentsline {subsection}{\numberline {2.0.4}Condiciones de convergencia uniforme casi segura}{52}{subsection.2.0.4}%
\contentsline {chapter}{\numberline {3}Otros conceptos del Aprendizaje}{55}{chapter.3}%
\contentsline {section}{\numberline {3.1}Consistencia de Bayes y error de aproximación}{55}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Espacios funcionales anidados}{56}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Regularización}{57}{subsection.3.1.2}%
\contentsline {section}{\numberline {3.2}Los teoremas de la chancha y los veinte}{59}{section.3.2}%
